{
    "name": "root",
    "gauges": {
        "Hider2V1.Policy.Entropy.mean": {
            "value": 2.8805084228515625,
            "min": 2.8805084228515625,
            "max": 3.0217692852020264,
            "count": 12
        },
        "Hider2V1.Policy.Entropy.sum": {
            "value": 135960.0,
            "min": 135960.0,
            "max": 155318.9375,
            "count": 12
        },
        "Hider2V1.Environment.EpisodeLength.mean": {
            "value": 82.79154929577464,
            "min": 64.39884393063583,
            "max": 203.76470588235293,
            "count": 12
        },
        "Hider2V1.Environment.EpisodeLength.sum": {
            "value": 58782.0,
            "min": 44563.0,
            "max": 59164.0,
            "count": 12
        },
        "Hider2V1.Step.mean": {
            "value": 599912.0,
            "min": 49989.0,
            "max": 599912.0,
            "count": 12
        },
        "Hider2V1.Step.sum": {
            "value": 599912.0,
            "min": 49989.0,
            "max": 599912.0,
            "count": 12
        },
        "Hider2V1.Policy.ExtrinsicValueEstimate.mean": {
            "value": -49491.296875,
            "min": -50303.671875,
            "max": -1048.68798828125,
            "count": 12
        },
        "Hider2V1.Policy.ExtrinsicValueEstimate.sum": {
            "value": -50431632.0,
            "min": -50431632.0,
            "max": -572583.625,
            "count": 12
        },
        "Hider2V1.Environment.CumulativeReward.mean": {
            "value": -48245.3380497528,
            "min": -110868.58499915698,
            "max": -26415.52231067963,
            "count": 12
        },
        "Hider2V1.Environment.CumulativeReward.sum": {
            "value": -34205944.677274734,
            "min": -36708944.334394805,
            "max": -18305956.961300984,
            "count": 12
        },
        "Hider2V1.Policy.ExtrinsicReward.mean": {
            "value": -48245.3380497528,
            "min": -110868.58499915698,
            "max": -26415.52231067963,
            "count": 12
        },
        "Hider2V1.Policy.ExtrinsicReward.sum": {
            "value": -34205944.677274734,
            "min": -36708944.334394805,
            "max": -18305956.961300984,
            "count": 12
        },
        "Hider2V1.Losses.PolicyLoss.mean": {
            "value": 0.06774644244833408,
            "min": 0.06670257586154699,
            "max": 0.07179034032495672,
            "count": 12
        },
        "Hider2V1.Losses.PolicyLoss.sum": {
            "value": 0.5419715395866727,
            "min": 0.5363059173716135,
            "max": 0.6414011265707884,
            "count": 12
        },
        "Hider2V1.Losses.ValueLoss.mean": {
            "value": 2644464118.0324717,
            "min": 1586009714.9861827,
            "max": 3631834437.702494,
            "count": 12
        },
        "Hider2V1.Losses.ValueLoss.sum": {
            "value": 21155712944.259773,
            "min": 13459890453.664944,
            "max": 29054675501.619953,
            "count": 12
        },
        "Hider2V1.Policy.LearningRate.mean": {
            "value": 0.00026559311646896496,
            "min": 0.00026559311646896496,
            "max": 0.00029835601554799497,
            "count": 12
        },
        "Hider2V1.Policy.LearningRate.sum": {
            "value": 0.0021247449317517196,
            "min": 0.0021247449317517196,
            "max": 0.0026058395113868395,
            "count": 12
        },
        "Hider2V1.Policy.Epsilon.mean": {
            "value": 0.188531035,
            "min": 0.188531035,
            "max": 0.19945200500000002,
            "count": 12
        },
        "Hider2V1.Policy.Epsilon.sum": {
            "value": 1.50824828,
            "min": 1.50824828,
            "max": 1.7686131600000001,
            "count": 12
        },
        "Hider2V1.Policy.Beta.mean": {
            "value": 0.0005000000000000002,
            "min": 0.0005000000000000002,
            "max": 0.0005000000000000002,
            "count": 12
        },
        "Hider2V1.Policy.Beta.sum": {
            "value": 0.004000000000000002,
            "min": 0.004000000000000002,
            "max": 0.004500000000000002,
            "count": 12
        },
        "Hider2V1.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 12
        },
        "Hider2V1.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 12
        },
        "Seeker2V1.Policy.Entropy.mean": {
            "value": 2.678621768951416,
            "min": 2.678621768951416,
            "max": 3.012482166290283,
            "count": 12
        },
        "Seeker2V1.Policy.Entropy.sum": {
            "value": 132792.671875,
            "min": 132792.671875,
            "max": 154916.890625,
            "count": 12
        },
        "Seeker2V1.Environment.EpisodeLength.mean": {
            "value": 54.59301014656144,
            "min": 54.59301014656144,
            "max": 226.11707317073171,
            "count": 12
        },
        "Seeker2V1.Environment.EpisodeLength.sum": {
            "value": 48424.0,
            "min": 46354.0,
            "max": 50967.0,
            "count": 12
        },
        "Seeker2V1.Step.mean": {
            "value": 599984.0,
            "min": 49887.0,
            "max": 599984.0,
            "count": 12
        },
        "Seeker2V1.Step.sum": {
            "value": 599984.0,
            "min": 49887.0,
            "max": 599984.0,
            "count": 12
        },
        "Seeker2V1.Policy.ExtrinsicValueEstimate.mean": {
            "value": 629.0388793945312,
            "min": 103.59364318847656,
            "max": 629.0388793945312,
            "count": 12
        },
        "Seeker2V1.Policy.ExtrinsicValueEstimate.sum": {
            "value": 657345.625,
            "min": 52418.3828125,
            "max": 657345.625,
            "count": 12
        },
        "Seeker2V1.Environment.CumulativeReward.mean": {
            "value": 925.76364911015,
            "min": 630.3902748482983,
            "max": 933.0850924561205,
            "count": 12
        },
        "Seeker2V1.Environment.CumulativeReward.sum": {
            "value": 821152.356760703,
            "min": 129230.00634390116,
            "max": 821152.356760703,
            "count": 12
        },
        "Seeker2V1.Policy.ExtrinsicReward.mean": {
            "value": 925.76364911015,
            "min": 630.3902748482983,
            "max": 933.0850924561205,
            "count": 12
        },
        "Seeker2V1.Policy.ExtrinsicReward.sum": {
            "value": 821152.356760703,
            "min": 129230.00634390116,
            "max": 821152.356760703,
            "count": 12
        },
        "Seeker2V1.Losses.PolicyLoss.mean": {
            "value": 0.06807349345763215,
            "min": 0.06526211986864736,
            "max": 0.0704996650970512,
            "count": 12
        },
        "Seeker2V1.Losses.PolicyLoss.sum": {
            "value": 0.8168819214915858,
            "min": 0.7754963160675633,
            "max": 0.8458654002175959,
            "count": 12
        },
        "Seeker2V1.Losses.ValueLoss.mean": {
            "value": 62569.05467563205,
            "min": 42106.27989915542,
            "max": 62569.05467563205,
            "count": 12
        },
        "Seeker2V1.Losses.ValueLoss.sum": {
            "value": 750828.6561075846,
            "min": 463169.0788907097,
            "max": 750828.6561075846,
            "count": 12
        },
        "Seeker2V1.Policy.LearningRate.mean": {
            "value": 0.00026559197646934497,
            "min": 0.00026559197646934497,
            "max": 0.00029836105690995095,
            "count": 12
        },
        "Seeker2V1.Policy.LearningRate.sum": {
            "value": 0.0031871037176321396,
            "min": 0.0031871037176321396,
            "max": 0.00354549655816782,
            "count": 12
        },
        "Seeker2V1.Policy.Epsilon.mean": {
            "value": 0.188530655,
            "min": 0.188530655,
            "max": 0.19945368545454548,
            "count": 12
        },
        "Seeker2V1.Policy.Epsilon.sum": {
            "value": 2.26236786,
            "min": 2.19399054,
            "max": 2.3818321800000004,
            "count": 12
        },
        "Seeker2V1.Policy.Beta.mean": {
            "value": 0.0005000000000000002,
            "min": 0.0005000000000000002,
            "max": 0.0005000000000000003,
            "count": 12
        },
        "Seeker2V1.Policy.Beta.sum": {
            "value": 0.006000000000000003,
            "min": 0.005500000000000003,
            "max": 0.006000000000000003,
            "count": 12
        },
        "Seeker2V1.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 12
        },
        "Seeker2V1.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 12
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1765487918",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Boris\\anaconda3\\envs\\mlagents\\Scripts\\mlagents-learn configurationTest.yaml --run-id hideandseek3-1 --train",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1765491177"
    },
    "total": 3258.5094288000255,
    "count": 1,
    "self": 0.013033200055360794,
    "children": {
        "run_training.setup": {
            "total": 0.14269529999000952,
            "count": 1,
            "self": 0.14269529999000952
        },
        "TrainerController.start_learning": {
            "total": 3258.35370029998,
            "count": 1,
            "self": 0.7604675012407824,
            "children": {
                "TrainerController._reset_env": {
                    "total": 47.19208070001332,
                    "count": 1,
                    "self": 47.19208070001332
                },
                "TrainerController.advance": {
                    "total": 3210.1317011987558,
                    "count": 29985,
                    "self": 0.953388100315351,
                    "children": {
                        "env_step": {
                            "total": 2349.0162931006635,
                            "count": 29985,
                            "self": 2072.787892905704,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 275.79883390205214,
                                    "count": 29985,
                                    "self": 4.5879520057933405,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 271.2108818962588,
                                            "count": 49588,
                                            "self": 271.2108818962588
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.42956629290711135,
                                    "count": 29984,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3147.9945752012427,
                                            "count": 29984,
                                            "is_parallel": true,
                                            "self": 1219.7388195105013,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.008148099936079234,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.002639499958604574,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00550859997747466,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00550859997747466
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1928.2476075908053,
                                                    "count": 29984,
                                                    "is_parallel": true,
                                                    "self": 10.279229499166831,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 15.678471300634556,
                                                            "count": 29984,
                                                            "is_parallel": true,
                                                            "self": 15.678471300634556
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1870.9249491009396,
                                                            "count": 29984,
                                                            "is_parallel": true,
                                                            "self": 1870.9249491009396
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 31.36495769006433,
                                                            "count": 59968,
                                                            "is_parallel": true,
                                                            "self": 9.832452588248998,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 21.53250510181533,
                                                                    "count": 119936,
                                                                    "is_parallel": true,
                                                                    "self": 21.53250510181533
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 860.162019997777,
                            "count": 59968,
                            "self": 2.035370101162698,
                            "children": {
                                "process_trajectory": {
                                    "total": 152.8409387965803,
                                    "count": 59968,
                                    "self": 152.40373639657628,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.43720240000402555,
                                            "count": 2,
                                            "self": 0.43720240000402555
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 705.285711100034,
                                    "count": 251,
                                    "self": 151.89684719534125,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 553.3888639046927,
                                            "count": 28671,
                                            "self": 553.3888639046927
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.26945089997025207,
                    "count": 1,
                    "self": 0.050357399974018335,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.21909349999623373,
                            "count": 2,
                            "self": 0.21909349999623373
                        }
                    }
                }
            }
        }
    }
}